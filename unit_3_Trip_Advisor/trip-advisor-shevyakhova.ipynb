{"cells":[{"metadata":{},"cell_type":"markdown","source":"#### Цель этого проекта: составить модель, которая будет предсказывать рейтинг ресторана на сайте Trip Advisor. Задача  - выделить характеристики ресторана, которые можно будет использовать в построении этой модели.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd  # импортируем все нужные библиотеки\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom itertools import combinations\nimport numpy as np\n\n# Загружаем специальный удобный инструмент для разделения датасета:\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# всегда фиксируйте RANDOM_SEED, чтобы ваши эксперименты были воспроизводимы!\nRANDOM_SEED = 42","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# зафиксируем версию пакетов, чтобы эксперименты были воспроизводимы:\n!pip freeze > requirements.txt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DATA_DIR = '/kaggle/input/trpadvsr/'\ndf_train = pd.read_csv('/kaggle/input/trpdvsr/main_task.csv')\ndf_test = pd.read_csv(DATA_DIR+'kaggle_task VS.csv')\nsample_submission = pd.read_csv(DATA_DIR+'sample_submission VS.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.info() #здесь мы имеем дело с базой данных Trip Advisor, содержащей 10 столбцов и 40 тыс. строк -\n#данные по 40 тыс. ресторанов, разделенные на 10 параметров","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ВАЖНО! дря корректной обработки признаков объединяем трейн и тест в один датасет\ndf_train['sample'] = 1 # помечаем где у нас трейн\ndf_test['sample'] = 0 # помечаем где у нас тест\ndf_test['Rating'] = 0 # в тесте у нас нет значения Rating, мы его должны предсказать, по этому пока просто заполняем нулями\n\ndf = df_test.append(df_train, sort=False).reset_index(drop=True) # объединяем","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info() #проверка - да все объединилось, как надо.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Что означают признаки:\n\nCity: Город,\nCuisine Style: Кухня,\nRanking: Ранг ресторана относительно других ресторанов в этом городе,\nPrice Range: Цены в ресторане в 3 категориях,\nNumber of Reviews: Количество отзывов,\nReviews: 2 последних отзыва и даты этих отзывов,\nURL_TA: страница ресторана на 'www.tripadvisor.com',\nID_TA: ID ресторана в TripAdvisor,\nRating: Рейтинг ресторана","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## City","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#проверим колонку \"город\" на наличие пропусков\ndf.City.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#дальше категориальные признаки нужно заменить числовыми. Сначала посмотрим на список городов и проверим,\n#нет ли неправильных написаний или каких-то других багов, которые могут дублировать значения\ndf['City'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Далее я попробовала сократить список значимых городов, но это никак не повлияло на модель, \n#поэтому я не вставляю этот шаг в финальное решение:\n#Всего у нас 40 тыс. записей, и если следовать формуле Парето 80/20, то нас интересуют только те города, которые\n#вносят вклад в 80% записей. это - 32 тыс. записей\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df['City'].value_counts()[:16].sum() # это - первые 16 городов, то есть половина всей выборки","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#city_short = df['City'].value_counts()[:16]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#city_short = city_short.reset_index()\n#city_short['index'].tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Оставим в базе только первые 16 городов - примерно половину, а остальные назовем other\n#city_set = set()\n#for item in city_short['index']:\n #   city_set.add(item)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#len(city_set)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#def find_item(cell):\n #   if item in cell:\n  #      return 1\n   # return 0\n#функция, которая вернет dummies в колонки с популярными городами","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#for item in city_set:\n #   df[item] = df['City'].apply(find_item)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#далее применим get_dummies:\ndf = pd.get_dummies(df, columns=['City'], dummy_na=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display(df.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['City_nan'].value_counts() #поскольку распределения нет, удалим эту колонку.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.drop('City_nan', axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Cuisine style","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#посмотрим, есть ли пропуски\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Cuisine Style'][0] #посмотрим, что надпись в ячейке организована как список разных видов кухонь","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Cuisine Style'] = df['Cuisine Style'].fillna('X]') #заменим пустые значения на X с лишней скобкой в конце для более простой обработки в дальнейшем","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Cuisine Style'] = df['Cuisine Style'].apply(lambda x: x[:-1]) #удалим лишние скобки в конце каждой строки. здесь нам и пригодилась скобка у empty","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Cuisine Style'] = df['Cuisine Style'].apply(lambda x: x.split(',')) #разделим кажду строку на элементы списка","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Cuisine Style'][1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(df['Cuisine Style'][0]) #проверим, разбились ли строки на список","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Cuisine Style'][0] #проверим, как выглядит список. Есть лишние кавычки.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#напишем функцию, которая очищает все элементы всех строк от лишних кавычек и запятых\ndef cut_c(line):\n    new_list=[]\n    for element in line:\n        if element=='X':\n            return 'X'\n        else:\n            new_list.append(element[2:-1])\n    return new_list","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Cuisine new'] = df['Cuisine Style'].apply(cut_c) #применим функцию","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Cuisine new'] #ура! Получилось! я избавилась от лишних скобок и всего прочего!!!","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cuisine_freq= pd.DataFrame(df['Cuisine new'].tolist()).stack().value_counts()\n# здесь я смотрю на распределение разных видов кухонь по популярности","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cuisine_freq = cuisine_freq.reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cuisine_freq.columns = ['index', 'freq']","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"pd.DataFrame(df['Cuisine new'].tolist()).stack().value_counts().sum()\n#посмотрим, сколько всего разных упоминаний кухонь в датасете","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(df['Cuisine new'].tolist()).stack().value_counts().sum() *0.8 #запуталась, как посчитать этот процентиль формулами,\n#поэтому делаю вручную: 80% от всех упоминаний кухнь это - 105012.8","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cuisine_freq.freq[:23].sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f_tolist = cuisine_freq['index'][0:23].tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Оставим в базе только первые 23 вида кухни - они составляют 80% всех упоминаний - а остальные назовем other","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cuisine_short_set = set()\nfor item in f_tolist:\n    cuisine_short_set.add(item)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def find_item(cell):\n    if item in cell:\n        return 1\n    return 0\n#функция, которая вернет dummies в колонки с типами кухонь","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for item in cuisine_short_set:\n    df[item] = df['Cuisine new'].apply(find_item)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape # к датасету прибавилось 23 колонки","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = df.copy() #сделаем копию на всякий пожарный","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## REVIEWS и выделение дат","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import datetime\nfrom datetime import datetime, timedelta\n# здесь я работаю с датами, которые содержатся в колонке Review: я их выделяю и перевожу в формат to_datetime","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Reviews'].isna() # есть два пропуска","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Reviews'] = data['Reviews'].fillna('no data')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Reviews'].isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Reviews'] = data['Reviews'].apply(lambda x: x.split(',')) #сначала я разделяю каждую запись в Review на элементы списка","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(data['Reviews'][1]) #проверим: теперь каждая запись - это список из нескольких элементов","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Reviews'][1] #первые два элемента - это текст отзыва, а вторые два - даты, когда был оставлен отзыв. Они-то нам и нужны!","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def cut_last(line): # эта функция выделит мне последние даты из каждой строки.\n    return line[-1][2:-3]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Reviews_lastdate'] = data['Reviews'].apply(cut_last) #применяю функцию к колонке и переношу все выделенные даты в отдельную колонку","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Reviews_lastdate'].isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Reviews_lastdate'] = data['Reviews_lastdate'].apply(lambda x: None if x == 'data' else x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def cut_first(line): # а эта функция выделит мне первые даты из каждой строки.\n    if len(line)>=2:\n        return line[-2][3:-1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Reviews_firstdate'] = data['Reviews'].apply(cut_first)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Reviews_firstdate'] = data['Reviews_firstdate'].apply(lambda x: x.lower() if x!= None else None) \n#с этой колонкой больше сложностей: в ней иногда попадается текст, написанный чем попало. поэтому на всякий случай\n#я перевожу весь текст в строчные буквы","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def cut_again(line):\n    if len(line)<2:\n        return None\n    elif len(line)>=2:\n        if line[0] == \"'\":\n            return line[1:]\n    else:\n        return line","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Reviews_lastdate'] = data['Reviews_lastdate'].apply(cut_again)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Reviews_lastdate'] = pd.to_datetime(data['Reviews_lastdate']) #перевожу данные в первой колонке в формат to_datetime","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def replace(line):\n    if 'e' in line:\n        return None\n    if 'a' in line:\n        return None\n    if 'r' in line:\n        return None\n    if 'i' in line:\n        return None\n    if 'o' in line:\n        return None\n    if 'u' in line:\n        return None\n    if 't' in line:\n        return None\n    if 'w' in line:\n        return None\n    if '厅' in line:\n        return None\n    if 'm' in line:\n        return None\n    if '/' not in line:\n        return None\n    return line\n#ищу текст в колонке и заменяю его на None","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[data['Reviews_firstdate'].isna()==True]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Reviews_firstdate'] = data['Reviews_firstdate'].fillna('o') \n#пока я none-значения не заменила на букву, у меня не работала функция....","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Reviews_firstdate'] = data['Reviews_firstdate'].apply(replace) \n#теперь я могу применитьфункцию по удалению текста","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Reviews_firstdate'].isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Reviews_firstdate'].isna().sum()\n#проверим, работает ли функция  - да, работает, в колонке появились NONE-значения","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Reviews_firstdate'] = pd.to_datetime(data['Reviews_firstdate'])\n#переведем в to_datetime","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Reviews_deltadates'] = data['Reviews_lastdate'] - data['Reviews_firstdate']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display(data.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(data['Reviews_deltadates'].describe(datetime_is_numeric=True)) # ну и вызовем статистику\nprint()\nprint(data['Reviews_firstdate'].describe(datetime_is_numeric=True))\nprint()\nprint(data['Reviews_lastdate'].describe(datetime_is_numeric=True))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['ordinal_firstdate']=data['Reviews_firstdate'].map(datetime.toordinal)\n#поскольку линейная регрессия не умеет работает с данными типа \"даты\", переведем все даты в ординальный формат","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['ordinal_lastdate']=data['Reviews_lastdate'].map(datetime.toordinal)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Reviews_lastdate'][10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['ordinal_timedelta'] = data['ordinal_lastdate'] - data['ordinal_firstdate']\n#здесь я создаю новую колонку - разница во времени между последним и первым отзывом. Возможно, это важно.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['ordinal_timedelta'] \n# и проверим, как это выглядит. интересно же. Отрицательные числа говорят о том, что\n# иногда дата в колонке firstdate оказывается более свежей, чем в колонке lastdate","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"latest = data.copy() \n#здесь я хочу создать еще одну колонку, в которой содержатся только самые свежие даты отзывов,\n#но специального метода не знаю, поэтому сделаю это как получается :) создаю копию датасета","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"latest = latest.loc[latest['ordinal_firstdate'] >= latest['ordinal_lastdate']]\n#выделяю в датасете только те строки, где дата из первой колонки- позже даты из второй колонки","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"latest","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"latest['latest_review_date'] = latest['ordinal_firstdate']\n# создаю новую колонку, в которую переношу самые свежие даты из ordinal first_date","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"latest2 = data.copy() #дальше повторяю всю ту же процедуру для другой колонки:","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"latest2 = latest2.loc[latest2['ordinal_firstdate'] < latest2['ordinal_lastdate']]\n#выделяю только те строки, где самые свежие даты содержатся в колонке lastdate","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"latest2['latest_review_date'] = latest2['ordinal_lastdate']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_df = pd.concat([latest, latest2], ignore_index=True) #объединяю два датасета, так что у меня теперь появляется новая целая колонка","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## хотя я и потратила кучу сил на то, чтобы создать эту отдельную колонку с самыми свежими датами ревью, однако она\n## она никак не улучшает модель.  Лучшие результаты достигаются с колонкой ordinal_lastdate или ordinal_timedelta","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## PRICE RANGE","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"new_df['Price Range'].isnull().sum() #посмотрим на количество пропусков","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_df['Price Range'].value_counts() # а это распределение разных ценовых категорий по датасету","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def price_range(x): # функция, которая меняет категориальное значение числовым. \n    if x == '$':\n        return 1\n    if x == '$$ - $$$':\n        return 2.5\n    if x == '$$$$':\n        return 4   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_df['price_range_index'] = new_df['Price Range'].apply(price_range) #создаю новую колонку с числовыми значениями","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#попробуем заменить NaN в пропорциональном соотношении:\n#общая сумма всех заполненных ячеек:\nprint(f'sum = {23041+7816+1782}')\nprint(f'1 = {7816/32639}')\nprint(f'2.5={23041/32639}')\nprint(f'4 = {1782/32639}')\nprint('Количество пропусков: ', new_df['price_range_index'].isna().sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#посчитаем, сколько каких значений нам нужно отдать пустым ячейкам:\nprint(f'1: {round(17359*0.23946)}')\nprint(f'2.5: {round(17359*0.705934)}')\nprint(f'4: {round(17359*0.05459)}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_df[new_df['price_range_index'].isna()][0:4157]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_df['price_range_index'] = new_df['price_range_index'][0:13235].fillna(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_df[new_df['price_range_index'].isna()][0:12255]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_df['price_range_index'] = new_df['price_range_index'][0:25490].fillna(2.5) #заполним 9790 ячеек значением 2.5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_df['price_range_index'] = new_df['price_range_index'].fillna(4) #остальные ячейки заполним значением 4","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_df['price_range_index'].isna().sum()  # проверяем - все пустые ячейки заполнены","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## number of reviews","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"new_df['Number of Reviews'].isna().sum() #посмотрим на пропуски в этой колонке","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_df['Number of Reviews'] = new_df['Number of Reviews'].fillna(0)\n#заполним их нулями - раз отзывов нет, значит, скорее всего, их, и правда, нет","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_df['Number of Reviews'].isna().sum() # проверим, как все заполнилось","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_df['Number of Reviews'].median() #посмотрим на медианное значение по количеству отзывов","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_df['Number of Reviews'].describe() # виден очень большой разброс между медианным и средним значением","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_df['Number of Reviews'].hist(bins=50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(new_df['Number of Reviews']); #посмотрим на выбросы на графике:","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"IQR = new_df['Number of Reviews'].quantile(0.75) - new_df['Number of Reviews'].quantile(0.25)\nperc25 = new_df['Number of Reviews'].quantile(0.25)\nperc75 = new_df['Number of Reviews'].quantile(0.75)\nprint('25 квантиль -', perc25, '75 квантиль -', perc75)\nprint(f'верхняя граница выбросов: {perc75+1.5*IQR}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"я попробовала избавиться от выбросов, но это ухудшает модель. Во-первых, их довольно много - около 15 процентов.\nво-вторых, большое количество отзывов как раз говорит о том, что это очень популярные рестораны -значит, они качественно значимы для датасета.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Ranking","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"new_df['Ranking'].isna().sum() #посмотрим на пропуски здесь","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_df['Ranking'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_df['Ranking'].hist();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(new_df['Ranking']); #похоже, есть выбросы","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"IQR = new_df.Ranking.quantile(0.75) - new_df.Ranking.quantile(0.25)\nperc25 = new_df.Ranking.quantile(0.25)\nperc75 = new_df.Ranking.quantile(0.75)\nprint(f'верхняя граница выбросов: {perc75+1.5*IQR}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#new_df.Ranking = new_df.Ranking.apply(lambda x: 0 if x >11645 else x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"я попробовала заменить выбросы нулями, но это ухудшило модель.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Rating","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"new_df.Rating.isna().sum()# в целевой переменной выбросов нет","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_df.Rating.describe() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_df.Rating.hist(bins=20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(new_df.Rating)\n#видно, что в основном рестораны получают средние оценки, с крепкой \"четверкой\" по медиане","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## финальное избавление от лишних столбцов:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"new_df.info()\n#нужно избавиться от столбцов с категориальными переменными и переменными типа datetime:","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_df = new_df.drop(['Restaurant_id', 'Cuisine new', 'Reviews_lastdate', 'Reviews_firstdate', 'Reviews_deltadates','Reviews', 'Price Range','Cuisine Style', 'ordinal_firstdate', 'ordinal_timedelta', 'latest_review_date', 'URL_TA', 'ID_TA'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Теперь выделим тестовую часть\ntrain_data = new_df.query('sample == 1').drop(['sample'], axis=1)\ntest_data = new_df.query('sample == 0').drop(['sample'], axis=1)\n\ny = train_data.Rating.values            # наш таргет\n#X = train_data.drop(['Rating'], axis=1)\nX = chance","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Перед тем как отправлять наши данные на обучение, разделим данные на еще один тест и трейн, для валидации. Это поможет нам проверить, как хорошо наша модель работает, до отправки submissiona на kaggle.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Воспользуемся специальной функцией train_test_split для разбивки тестовых данных\n# выделим 20% данных на валидацию (параметр test_size)\n# Загружаем специальный инструмент для разбивки:\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# проверяем\ntest_data.shape, train_data.shape, X.shape, X_train.shape, X_test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Создаём, обучаем и тестируем модель","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Импортируем необходимые библиотеки:\nfrom sklearn.ensemble import RandomForestRegressor # инструмент для создания и обучения модели\nfrom sklearn import metrics # инструменты для оценки точности модели","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Создаём модель\nregr = RandomForestRegressor(n_estimators=100, verbose=1, n_jobs=-1, random_state=RANDOM_SEED)\n\n# Обучаем модель на тестовом наборе данных\nregr.fit(X_train, y_train)\n\n# Используем обученную модель для предсказания рейтинга ресторанов в тестовой выборке.\n# Предсказанные значения записываем в переменную y_pred\ny_pred = regr.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Сравниваем предсказанные значения (y_pred) с реальными (y_test), и смотрим насколько они в среднем отличаются\n# Метрика называется Mean Absolute Error (MAE) и показывает среднее отклонение предсказанных значений от фактических.\nprint('MAE:', metrics.mean_absolute_error(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Submission на Kaggle","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data = test_data.drop(['Rating'], axis=1) #возьмем датасет, выделенный специально для тестирования модели, ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_submission = regr.predict(test_data) #применим предсказательную модель к тестовому датасету","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_submission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission['Rating'] = predict_submission #перезапишем столбец Rating с учетом новых данных","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission.to_csv('submission_draft11.csv', index=False) # и запишем новый результат в файл","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}